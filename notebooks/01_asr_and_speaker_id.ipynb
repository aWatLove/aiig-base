{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 — ASR и идентификация говорящего\n",
        "\n",
        "Цель ноутбука — показать базовый прототип:\n",
        "- локального распознавания речи (ASR) с помощью `faster-whisper` (и при желании Vosk);\n",
        "- извлечения эмбеддингов говорящего с помощью `speechbrain`;\n",
        "- простого мэппинга говорящего к пользователю и его пресетам.\n",
        "\n",
        "Допущения:\n",
        "- работаем оффлайн, без платных API;\n",
        "- целевая платформа — ноутбук (1660 Ti / Macbook M‑серии) и сервер с/без GPU.\n",
        "\n",
        "В конце ноутбука должны быть:\n",
        "- функция для обработки аудиофайла/чанка и возврата `[text, speaker_embedding]`;\n",
        "- простой пример базы пользователей и сопоставления эмбеддингов с пользователями.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Базовые импорты и конфигурация\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# ASR\n",
        "from faster_whisper import WhisperModel\n",
        "\n",
        "# Speaker embeddings\n",
        "from speechbrain.pretrained import EncoderClassifier\n",
        "\n",
        "\n",
        "DEVICE = \"cuda\" if os.environ.get(\"USE_CUDA\", \"0\") == \"1\" else \"cpu\"\n",
        "MODEL_SIZE = \"small\"  # можно переключать на tiny / base для слабых машин\n",
        "\n",
        "\n",
        "def load_asr_model(model_size: str = MODEL_SIZE, device: str = DEVICE):\n",
        "    \"\"\"Загружает модель faster-whisper для оффлайн ASR.\"\"\"\n",
        "    compute_type = \"float16\" if device == \"cuda\" else \"int8\"\n",
        "    model = WhisperModel(model_size, device=device, compute_type=compute_type)\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_speaker_encoder():\n",
        "    \"\"\"Загружает энкодер голосовых эмбеддингов (speechbrain).\"\"\"\n",
        "    encoder = EncoderClassifier.from_hparams(\n",
        "        source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
        "        savedir=\"pretrained_models/spkrec-ecapa-voxceleb\",\n",
        "    )\n",
        "    return encoder\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Загрузка и предобработка аудио\n",
        "\n",
        "В этом разделе:\n",
        "- загружаем аудио-файл локально;\n",
        "- приводим к моно и частоте дискретизации 16 кГц;\n",
        "- готовим данные для ASR и энкодера говорящего.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Загрузка и предобработка аудио\n",
        "\n",
        "from typing import Tuple\n",
        "\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "\n",
        "TARGET_SR = 16_000\n",
        "\n",
        "\n",
        "def load_audio_mono(path: str | Path, target_sr: int = TARGET_SR) -> Tuple[np.ndarray, int]:\n",
        "    \"\"\"Загружает аудио в моно, приводит к нужной частоте дискретизации.\"\"\"\n",
        "    path = Path(path)\n",
        "    audio, sr = sf.read(path)\n",
        "\n",
        "    # Приводим к моно\n",
        "    if audio.ndim > 1:\n",
        "        audio = audio.mean(axis=1)\n",
        "\n",
        "    # Приводим к нужной частоте дискретизации\n",
        "    if sr != target_sr:\n",
        "        audio = librosa.resample(audio, orig_sr=sr, target_sr=target_sr)\n",
        "        sr = target_sr\n",
        "\n",
        "    # Нормализация (опционально)\n",
        "    if np.max(np.abs(audio)) > 0:\n",
        "        audio = audio / np.max(np.abs(audio))\n",
        "\n",
        "    return audio.astype(\"float32\"), sr\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Транскрипция и эмбеддинг говорящего\n",
        "\n",
        "Теперь напишем функции, которые:\n",
        "- принимают путь к аудио;\n",
        "- используют одну и ту же волну для ASR и speaker encoder;\n",
        "- возвращают текст и вектор эмбеддинга.\n",
        "\n",
        "Для простоты берём весь файл как единый фрагмент (позже можно нарезать на чанки для онлайн-сценария).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Транскрипция и эмбеддинг говорящего\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "def transcribe_and_embed(\n",
        "    audio_path: str | Path,\n",
        "    asr_model: WhisperModel,\n",
        "    speaker_encoder: EncoderClassifier,\n",
        "    language: str | None = None,\n",
        "):\n",
        "    \"\"\"Возвращает (полный текст, список сегментов, эмбеддинг говорящего).\"\"\"\n",
        "    audio, sr = load_audio_mono(audio_path, target_sr=TARGET_SR)\n",
        "\n",
        "    # ASR (faster-whisper поддерживает numpy-массивы)\n",
        "    segments, info = asr_model.transcribe(\n",
        "        audio=audio,\n",
        "        language=language,  # None = автоопределение\n",
        "    )\n",
        "\n",
        "    all_segments = list(segments)\n",
        "    full_text = \" \".join(seg.text.strip() for seg in all_segments)\n",
        "\n",
        "    # Speaker embedding через speechbrain\n",
        "    waveform = torch.from_numpy(audio).float().unsqueeze(0)  # (1, T)\n",
        "    with torch.no_grad():\n",
        "        emb = speaker_encoder.encode_batch(waveform)\n",
        "    # Обычно размер (1, 1, D) → приводим к (D,)\n",
        "    emb = emb.squeeze(0).squeeze(0).cpu().numpy()\n",
        "\n",
        "    return full_text, all_segments, emb\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Простая база пользователей и пресетов\n",
        "\n",
        "Сделаем очень простую модель базы пользователей:\n",
        "- у каждого пользователя есть `user_id`, вектор эмбеддинга и словарь пресетов;\n",
        "- при новом эмбеддинге ищем ближайшего пользователя по косинусному сходству;\n",
        "- если сходство ниже порога — создаём нового пользователя.\n",
        "\n",
        "Это заготовка, которую потом можно вынести в отдельный сервис (`user_preset_service`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Простая база пользователей\n",
        "\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class User:\n",
        "    user_id: str\n",
        "    embedding: np.ndarray\n",
        "    presets: Dict[str, str] = field(default_factory=dict)\n",
        "\n",
        "\n",
        "class UserDB:\n",
        "    def __init__(self, similarity_threshold: float = 0.7):\n",
        "        self.users: List[User] = []\n",
        "        self.similarity_threshold = similarity_threshold\n",
        "\n",
        "    @staticmethod\n",
        "    def _cosine_sim(a: np.ndarray, b: np.ndarray) -> float:\n",
        "        a = a / (np.linalg.norm(a) + 1e-8)\n",
        "        b = b / (np.linalg.norm(b) + 1e-8)\n",
        "        return float(np.dot(a, b))\n",
        "\n",
        "    def add_user(self, embedding: np.ndarray, user_id: Optional[str] = None, presets: Optional[Dict[str, str]] = None) -> User:\n",
        "        if user_id is None:\n",
        "            user_id = f\"user_{len(self.users) + 1}\"\n",
        "        user = User(user_id=user_id, embedding=embedding, presets=presets or {})\n",
        "        self.users.append(user)\n",
        "        return user\n",
        "\n",
        "    def match_user(self, embedding: np.ndarray) -> Tuple[Optional[User], float]:\n",
        "        if not self.users:\n",
        "            return None, 0.0\n",
        "        best_user = None\n",
        "        best_sim = -1.0\n",
        "        for user in self.users:\n",
        "            sim = self._cosine_sim(embedding, user.embedding)\n",
        "            if sim > best_sim:\n",
        "                best_sim = sim\n",
        "                best_user = user\n",
        "        if best_sim < self.similarity_threshold:\n",
        "            return None, best_sim\n",
        "        return best_user, best_sim\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Пример использования на одном аудиофайле\n",
        "\n",
        "Ниже — примерный сценарий:\n",
        "1. Загружаем модели ASR и speaker encoder.\n",
        "2. Обрабатываем аудиофайл (например, речь Кирилла).\n",
        "3. Пытаемся найти пользователя в базе; если не нашли — создаём нового с пресетами.\n",
        "\n",
        "Ты можешь положить свои аудиофайлы в папку `data/audio/` и подставить путь.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Пример использования\n",
        "\n",
        "# Путь к аудио (замени на свой файл, например, data/audio/kirill_1.wav)\n",
        "audio_path = \"data/audio/example_speaker.wav\"\n",
        "\n",
        "# 1. Загружаем модели (может занять время при первом запуске)\n",
        "asr_model = load_asr_model()\n",
        "speaker_encoder = load_speaker_encoder()\n",
        "\n",
        "# 2. Выполняем транскрипцию и получаем эмбеддинг\n",
        "text, segments, emb = transcribe_and_embed(audio_path, asr_model, speaker_encoder, language=None)\n",
        "print(\"Recognized text:\\n\", text)\n",
        "\n",
        "# 3. Работаем с базой пользователей\n",
        "user_db = UserDB(similarity_threshold=0.7)\n",
        "\n",
        "# Пример заранее добавленного пользователя \"Кирилл\"\n",
        "kirill = user_db.add_user(\n",
        "    embedding=emb,  # в реальности лучше усреднить несколько записей\n",
        "    user_id=\"kirill\",\n",
        "    presets={\n",
        "        \"style\": \"cinematic, high contrast, dark blue palette\",\n",
        "        \"character\": \"male character resembling Kirill\",\n",
        "    },\n",
        ")\n",
        "\n",
        "matched_user, sim = user_db.match_user(emb)\n",
        "print(f\"Matched user: {matched_user.user_id if matched_user else None}, similarity={sim:.3f}\")\n",
        "\n",
        "# В дальнейшем пресеты matched_user можно использовать при формировании промпта для генерации изображений.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
