{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03 — Быстрая генерация изображений и бенчмарки\n",
        "\n",
        "Цель ноутбука — исследовать скорость и качество генерации на разных настройках и железе:\n",
        "- стандартный Stable Diffusion vs Turbo/LCM варианты (меньше шагов);\n",
        "- влияние разрешения, числа шагов и типа сэмплера на время и качество;\n",
        "- базовый эксперимент с экспортом в ONNX Runtime.\n",
        "\n",
        "Результат ноутбука:\n",
        "- таблица/графики со временем генерации и субъективной оценкой качества;\n",
        "- рекомендации по настройкам для ноутбука и сервера.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Импорты для бенчмарков скорости\n",
        "\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BASE_MODEL_ID = \"runwayml/stable-diffusion-v1-5\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class BenchmarkConfig:\n",
        "    model_id: str\n",
        "    steps: int\n",
        "    height: int\n",
        "    width: int\n",
        "    batch_size: int = 1\n",
        "\n",
        "\n",
        "def load_pipe(model_id: str):\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(\n",
        "        model_id,\n",
        "        torch_dtype=torch.float16 if DEVICE == \"cuda\" else torch.float32,\n",
        "    )\n",
        "    pipe = pipe.to(DEVICE)\n",
        "    pipe.safety_checker = None\n",
        "    return pipe\n",
        "\n",
        "\n",
        "def benchmark_generation(pipe, config: BenchmarkConfig, prompt: str = \"a scenic landscape\"):\n",
        "    \"\"\"Простой замер времени одной генерации.\"\"\"\n",
        "    start = time.time()\n",
        "    _ = pipe(\n",
        "        prompt=[prompt] * config.batch_size,\n",
        "        num_inference_steps=config.steps,\n",
        "        height=config.height,\n",
        "        width=config.width,\n",
        "    ).images\n",
        "    end = time.time()\n",
        "    return end - start\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
