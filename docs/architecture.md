## Архитектура системы генерации изображений по голосу

Цель: обеспечить генерацию изображений **в режиме близком к реальному времени** (5–10 секунд) по голосу участников онлайн-встречи, с учётом:
- личности говорящего (пресеты, история);
- контекста беседы;
- референсных изображений / стилей;
- работы как на ноутбуке (1660 Ti / Macbook M4), так и на сервере с/без GPU.

### Высокоуровневые компоненты

1. **ASR-сервис (Speech-to-Text + Speaker Embeddings)**
   - Получает аудиопоток или чанки аудио.
   - Использует:
     - `faster-whisper` для распознавания текста;
     - `speechbrain` для извлечения эмбеддингов говорящего.
   - Возвращает:
     - текст фразы;
     - идентификатор говорящего (ID пользователя или новый эмбеддинг);
     - временные метки.

2. **User & Preset Service**
   - Хранит информацию о пользователях: голосовые эмбеддинги, имя, пресеты стиля, историю.
   - При получении нового эмбеддинга:
     - находит ближайшего пользователя (метрика в эмбеддинговом пространстве);
     - или создаёт нового пользователя.
   - Выдаёт:
     - ID пользователя;
     - параметры генерации (цветовая палитра, стиль, сюжетные предпочтения).

3. **Context & Prompt Orchestrator**
   - Принимает поток фраз от ASR-сервиса (с говорящим).
   - Поддерживает «окно контекста» (последние N минут обсуждения).
   - Строит текстовый промпт для генерации:
     - на основе текущих фраз;
     - с учётом истории и пресетов пользователя;
     - с учётом референсных изображений (если заданы).
   - Периодически (например, раз в 10–20 секунд) инициирует генерацию нового изображения.

4. **Image Generation Service**
   - На основе:
     - текстового промпта;
     - ссылок на референсные изображения (img2img / стилизация);
     - параметров стиля из пресетов.
   - Использует:
     - `diffusers` + Stable Diffusion / SDXL;
     - быстрые варианты (SD Turbo, LCM) для уменьшения числа шагов.
   - Опционально:
     - экспорт части пайплайна в ONNX Runtime для ускорения.

5. **Front-end / Meeting Visualizer**
   - Простое веб-приложение, которое:
     - показывает текущее/последние изображения;
     - отображает, какие участники говорили;
     - опционально показывает текстовые субтитры.

### Потоковая обработка (streaming-пайплайн)

Потоковость в системе достигается за счёт работы с **непрерывными аудиоданными как с последовательностью чанков** и периодической генерации кадров:

1. **Захват аудио на клиенте**
   - Клиент (desktop/web) захватывает микрофон и разбивает поток на чанки по 1–3 секунды.
   - Каждый чанк отправляется в `asr_service` как отдельный запрос (эмуляция стрима).

2. **ASR-сервис (чанк → текст + эмбеддинг)**
   - Держит в памяти загруженные модели `WhisperModel` и `speechbrain` (инициализация один раз при старте).
   - Для каждого чанка:
     - выполняет `transcribe` по numpy-вектору аудио;
     - извлекает эмбеддинг говорящего из того же чанка;
     - возвращает короткий текст фрагмента, временные метки и эмбеддинг (или предварительный speaker_id).

3. **Orchestrator (инкрементальный контекст)**
   - При каждом вызове `POST /ingest_utterance` добавляет новую реплику в `MeetingState`.
   - Хранит только последние `max_history_seconds` истории (старые utterances отбрасываются).
   - По запросу (или по таймеру) строит промпт по последним репликам (`build_prompt`) — таким образом контекст обновляется инкрементально.

4. **Image-service (последовательная генерация кадров)**
   - Хранит в памяти один экземпляр диффузионного пайплайна (Stable Diffusion / Turbo / LCM).
   - Обрабатывает входящие запросы на генерацию **последовательно** (очередь), что делает поведение предсказуемым во времени.
   - Каждый успешный вызов порождает новый кадр (изображение), который фронтенд отображает как очередное состояние беседы.

5. **Визуальный поток**
   - Клиент/фронтенд периодически (раз в N секунд) или по событиям вызывает `/trigger_generation` в orchestrator’е, который, в свою очередь, обращается к `image_service`.
   - В результате на экране участников отображается **поток сменяющихся кадров**, отражающих эволюцию темы и настроения встречи.

### Микросервисная схема (черновой вариант)

Предлагаемая схема микросервисов:

- `asr_service` (FastAPI)
  - Эндпоинты:
    - `POST /transcribe` — загрузка чанка аудио → текст, speaker embedding, timestamps.
  - Тяжёлые модели: `faster-whisper`, `speechbrain`.

- `user_preset_service` (FastAPI)
  - Эндпоинты:
    - `POST /match_or_create_user` — эмбеддинг → user_id + пресеты.
    - `GET /user/{user_id}` — параметры пользователя и история.

- `orchestrator_service` (FastAPI / WebSocket)
  - Получает от `asr_service`:
    - текст, user_id, timestamps.
  - Управляет буфером контекста и референсами.
  - Эндпоинты:
    - `POST /ingest_utterance` — новая фраза.
    - `POST /trigger_generation` — явный вызов генерации (или по таймеру внутри сервиса).

- `image_service` (FastAPI)
  - Эндпоинты:
    - `POST /generate` — промпт + настройки → изображение (URL/байты).
  - Хранит текущие веса модели, применяет оптимизации (Turbo/LCM/ONNX).

### Запуск на разных типах железа

1. **Ноутбук с 1660 Ti / Macbook M4**
   - Режим «всё в одном»:
     - один процесс, в котором работают все компоненты;
     - меньший размер модели (SD 1.5, компактные Turbo/LCM варианты).
   - Снижение нагрузки:
     - уменьшенное разрешение (например, 512x512);
     - 4–8 шагов диффузии;
     - использование mixed precision / квантования.

2. **Сервер с GPU**
   - Разнести сервисы:
     - `asr_service` и `image_service` могут использовать разные GPU или очереди.
   - Увеличить качество:
     - более крупные модели (SDXL);
     - дополнительные ControlNet-модули.

3. **Сервер без GPU**
   - Эксперименты с ONNX Runtime и квантованием:
     - меньшие модели ASR (tiny/base);
     - быстрые / облегчённые диффузионные модели.

### Роль MLflow

- Логирование экспериментов:
  - версия модели ASR + параметры;
  - версия модели генерации + количество шагов, разрешение, ускорения.
- Метрики:
  - среднее время отклика (от конца речи до готового изображения);
  - использование памяти/VRAM;
  - субъективная оценка качества (через аннотации).
- Сохранение артефактов:
  - сгенерированные изображения;
  - промпты и настройки;
  - конфигурации микросервисов.

---

В ноутбуках и коде микросервисов эта архитектура будет реализована поэтапно:
- сначала — монолитные прототипы в `ipynb`;
- затем — вынесение функционала в отдельные FastAPI-сервисы.


