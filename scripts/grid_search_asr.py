"""
Grid Search Benchmark –¥–ª—è Voice-to-Text –Ω–∞ MacBook Air M4.

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ faster-whisper
—Å —É—á–µ—Ç–æ–º —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ —Ç–æ—á–Ω–æ—Å—Ç–∏.
"""

import csv
import gc
import sys
import time
from itertools import product
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
import psutil
import soundfile as sf
from tqdm import tqdm

sys.path.insert(0, str(Path(__file__).parent.parent / "services" / "v2t_service" / "src"))

from v2t.asr.whisper_impl import FasterWhisperEngine


def load_audio(path: Path, target_sr: int = 16000) -> Tuple[np.ndarray, float]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∞—É–¥–∏–æ —Ñ–∞–π–ª –∏ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –Ω—É–∂–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É.
    
    Args:
        path: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É
        target_sr: –¶–µ–ª–µ–≤–∞—è —á–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
        
    Returns:
        –ö–æ—Ä—Ç–µ–∂ (–∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ, –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ —Å–µ–∫—É–Ω–¥–∞—Ö)
    """
    try:
        audio, sr = sf.read(str(path))
    except:
        import librosa
        audio, sr = librosa.load(str(path), sr=None, mono=False)
    
    if audio.ndim > 1:
        audio = audio.mean(axis=0)
    
    if sr != target_sr:
        import librosa
        audio = librosa.resample(audio, orig_sr=sr, target_sr=target_sr)
    
    if np.max(np.abs(audio)) > 0:
        audio = audio / np.max(np.abs(audio))
    
    duration = len(audio) / target_sr
    return audio.astype(np.float32), duration


def load_audio_files(data_dir: Path, max_files: int = 20) -> List[Tuple[Path, np.ndarray, float]]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ –∞—É–¥–∏–æ —Ñ–∞–π–ª—ã.
    
    Args:
        data_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞–º–∏
        max_files: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤
        
    Returns:
        –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (–ø—É—Ç—å, –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ, –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å)
    """
    audio_extensions = {'.wav', '.mp3', '.opus', '.flac', '.m4a', '.ogg'}
    audio_files = [
        f for f in data_dir.rglob('*')
        if f.is_file() and f.suffix.lower() in audio_extensions and 'synthetic' not in str(f)
    ]
    
    if len(audio_files) < max_files:
        print(f"‚ö† –ù–∞–π–¥–µ–Ω–æ —Ç–æ–ª—å–∫–æ {len(audio_files)} —Ñ–∞–π–ª–æ–≤, —Ç—Ä–µ–±—É–µ—Ç—Å—è {max_files}")
        max_files = len(audio_files)
    
    selected_files = audio_files[:max_files]
    print(f"–ó–∞–≥—Ä—É–∑–∫–∞ {len(selected_files)} —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤...")
    
    loaded_files = []
    for file_path in tqdm(selected_files, desc="–ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ"):
        try:
            audio, duration = load_audio(file_path)
            loaded_files.append((file_path, audio, duration))
        except Exception as e:
            print(f"‚ö† –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {file_path.name}: {e}")
    
    total_duration = sum(d for _, _, d in loaded_files)
    print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(loaded_files)} —Ñ–∞–π–ª–æ–≤, –æ–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {total_duration:.2f} —Å–µ–∫ ({total_duration/60:.2f} –º–∏–Ω)\n")
    
    return loaded_files


def generate_grid_combinations() -> List[Dict]:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≤—Å–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è grid search.
    
    Returns:
        –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π
    """
    model_sizes = ["tiny", "base", "small", "medium"]
    compute_types = ["int8", "float32"]
    cpu_threads_list = [2, 4, 8]
    beam_sizes = [1, 2, 5]
    vad_filters = [True, False]
    
    combinations = []
    for model_size, compute_type, cpu_threads, beam_size, vad_filter in product(
        model_sizes, compute_types, cpu_threads_list, beam_sizes, vad_filters
    ):
        combinations.append({
            "model_size": model_size,
            "compute_type": compute_type,
            "cpu_threads": cpu_threads,
            "beam_size": beam_size,
            "vad_filter": vad_filter
        })
    
    return combinations


def test_configuration(
    config: Dict,
    audio_files: List[Tuple[Path, np.ndarray, float]]
) -> Dict:
    """
    –¢–µ—Å—Ç–∏—Ä—É–µ—Ç –æ–¥–Ω—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.
    
    Args:
        config: –°–ª–æ–≤–∞—Ä—å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        audio_files: –°–ø–∏—Å–æ–∫ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    """
    result = {
        **config,
        "init_time": 0.0,
        "total_processing_time": 0.0,
        "total_audio_duration": 0.0,
        "rtf": 0.0,
        "avg_confidence": 0.0,
        "peak_memory_mb": 0.0,
        "success": False,
        "error": None
    }
    
    process = psutil.Process()
    memory_before = process.memory_info().rss / 1024 / 1024
    
    try:
        init_start = time.time()
        engine = FasterWhisperEngine(
            model_size=config["model_size"],
            device="cpu",
            compute_type=config["compute_type"],
            cpu_threads=config["cpu_threads"]
        )
        init_time = time.time() - init_start
        result["init_time"] = init_time
        
        total_duration = 0.0
        total_processing_time = 0.0
        all_confidences = []
        peak_memory = memory_before
        
        for file_path, audio, duration in audio_files:
            total_duration += duration
            
            process_start = time.time()
            utterances = engine.transcribe(
                audio,
                beam_size=config["beam_size"],
                vad_filter=config["vad_filter"]
            )
            process_time = time.time() - process_start
            total_processing_time += process_time
            
            if utterances:
                confidences = [u.confidence for u in utterances]
                all_confidences.extend(confidences)
            
            current_memory = process.memory_info().rss / 1024 / 1024
            peak_memory = max(peak_memory, current_memory)
        
        result["total_audio_duration"] = total_duration
        result["total_processing_time"] = total_processing_time
        result["rtf"] = total_processing_time / total_duration if total_duration > 0 else 0.0
        result["avg_confidence"] = np.mean(all_confidences) if all_confidences else 0.0
        result["peak_memory_mb"] = peak_memory - memory_before
        result["success"] = True
        
        del engine
        gc.collect()
        
    except Exception as e:
        result["error"] = str(e)
        result["success"] = False
        gc.collect()
    
    return result


def save_results_csv(results: List[Dict], filename: Path):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ CSV —Ñ–∞–π–ª.
    
    Args:
        results: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        filename: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    """
    if not results:
        return
    
    fieldnames = [
        "model_size", "compute_type", "cpu_threads", "beam_size", "vad_filter",
        "init_time", "total_processing_time", "total_audio_duration", "rtf",
        "avg_confidence", "peak_memory_mb", "success", "error"
    ]
    
    with open(filename, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(results)
    
    print(f"‚úì –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ CSV: {filename}")


def generate_markdown_report(results: List[Dict], filename: Path):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç Markdown –æ—Ç—á–µ—Ç —Å —Ç–∞–±–ª–∏—Ü–µ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.
    
    Args:
        results: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        filename: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    """
    successful = [r for r in results if r["success"]]
    
    if not successful:
        with open(filename, "w", encoding="utf-8") as f:
            f.write("# Grid Search Results\n\n")
            f.write("‚ùå –ù–µ—Ç —É—Å–ø–µ—à–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.\n")
        return
    
    successful.sort(key=lambda x: x["rtf"])
    
    lines = []
    lines.append("# Grid Search ASR Benchmark Results\n")
    lines.append(f"**–í—Å–µ–≥–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π:** {len(results)}\n")
    lines.append(f"**–£—Å–ø–µ—à–Ω—ã—Ö:** {len(successful)}\n")
    lines.append(f"**–ù–µ—É–¥–∞—á–Ω—ã—Ö:** {len(results) - len(successful)}\n\n")
    
    lines.append("## –¢–æ–ø-10 –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π –ø–æ —Å–∫–æ—Ä–æ—Å—Ç–∏ (RTF)\n")
    lines.append("| Rank | Model | Compute | Threads | Beam | VAD | RTF | Confidence | Memory (MB) | Init (s) |\n")
    lines.append("|------|-------|---------|---------|------|-----|-----|------------|-------------|----------|\n")
    
    for i, result in enumerate(successful[:10], 1):
        lines.append(
            f"| {i} | {result['model_size']} | {result['compute_type']} | "
            f"{result['cpu_threads']} | {result['beam_size']} | "
            f"{'‚úì' if result['vad_filter'] else '‚úó'} | "
            f"{result['rtf']:.4f} | {result['avg_confidence']:.3f} | "
            f"{result['peak_memory_mb']:.1f} | {result['init_time']:.2f} |\n"
        )
    
    lines.append("\n## –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –º–æ–¥–µ–ª—è–º\n")
    lines.append("| Model | Avg RTF | Best RTF | Avg Confidence | Avg Memory (MB) |\n")
    lines.append("|-------|---------|----------|----------------|-----------------|\n")
    
    for model_size in ["tiny", "base", "small", "medium"]:
        model_results = [r for r in successful if r["model_size"] == model_size]
        if model_results:
            avg_rtf = np.mean([r["rtf"] for r in model_results])
            best_rtf = min([r["rtf"] for r in model_results])
            avg_conf = np.mean([r["avg_confidence"] for r in model_results])
            avg_mem = np.mean([r["peak_memory_mb"] for r in model_results])
            
            lines.append(
                f"| {model_size} | {avg_rtf:.4f} | {best_rtf:.4f} | "
                f"{avg_conf:.3f} | {avg_mem:.1f} |\n"
            )
    
    failed = [r for r in results if not r["success"]]
    if failed:
        lines.append("\n## –û—à–∏–±–∫–∏\n")
        lines.append("| Model | Compute | Threads | Beam | VAD | Error |\n")
        lines.append("|-------|---------|---------|------|-----|-------|\n")
        
        for result in failed[:10]:
            error_msg = result["error"][:50] + "..." if len(result["error"]) > 50 else result["error"]
            lines.append(
                f"| {result['model_size']} | {result['compute_type']} | "
                f"{result['cpu_threads']} | {result['beam_size']} | "
                f"{'‚úì' if result['vad_filter'] else '‚úó'} | {error_msg} |\n"
            )
    
    with open(filename, "w", encoding="utf-8") as f:
        f.writelines(lines)
    
    print(f"‚úì Markdown –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filename}")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è grid search."""
    import argparse
    
    parser = argparse.ArgumentParser(description="Grid Search Benchmark –¥–ª—è ASR")
    parser.add_argument(
        "data_dir",
        type=Path,
        help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞–º–∏"
    )
    parser.add_argument(
        "--max-files",
        type=int,
        default=20,
        help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 20)"
    )
    parser.add_argument(
        "--output-dir",
        type=Path,
        help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é data/open_stt/test_results)"
    )
    
    args = parser.parse_args()
    
    if not args.data_dir.exists():
        print(f"‚ùå –û—à–∏–±–∫–∞: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {args.data_dir}")
        sys.exit(1)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    if args.output_dir:
        output_dir = args.output_dir
    else:
        output_dir = Path(__file__).parent.parent / "data" / "open_stt" / "test_results"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print("=" * 80)
    print("GRID SEARCH ASR BENCHMARK")
    print("=" * 80)
    print(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –¥–∞–Ω–Ω—ã–º–∏: {args.data_dir}")
    print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤: {args.max_files}")
    print(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {output_dir}\n")
    
    audio_files = load_audio_files(args.data_dir, args.max_files)
    
    if not audio_files:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
        sys.exit(1)
    
    combinations = generate_grid_combinations()
    print(f"–í—Å–µ–≥–æ –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {len(combinations)}\n")
    
    results = []
    print("–ù–∞—á–∞–ª–æ grid search...\n")
    
    for config in tqdm(combinations, desc="Grid Search"):
        config_str = (
            f"{config['model_size']}/{config['compute_type']}/"
            f"threads={config['cpu_threads']}/beam={config['beam_size']}/"
            f"vad={config['vad_filter']}"
        )
        
        result = test_configuration(config, audio_files)
        results.append(result)
        
        if len(results) % 10 == 0:
            save_results_csv(results, output_dir / "grid_search_results_intermediate.csv")
    
    csv_file = output_dir / "grid_search_results.csv"
    save_results_csv(results, csv_file)
    
    md_file = output_dir / "grid_search_report.md"
    generate_markdown_report(results, md_file)
    
    successful = [r for r in results if r["success"]]
    failed = [r for r in results if not r["success"]]
    
    print("\n" + "=" * 80)
    print("–ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print("=" * 80)
    print(f"–í—Å–µ–≥–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π: {len(results)}")
    print(f"–£—Å–ø–µ—à–Ω—ã—Ö: {len(successful)}")
    print(f"–ù–µ—É–¥–∞—á–Ω—ã—Ö: {len(failed)}")
    
    if successful:
        best = min(successful, key=lambda x: x["rtf"])
        print(f"\nüèÜ –õ—É—á—à–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (RTF={best['rtf']:.4f}):")
        print(f"   Model: {best['model_size']}")
        print(f"   Compute: {best['compute_type']}")
        print(f"   Threads: {best['cpu_threads']}")
        print(f"   Beam: {best['beam_size']}")
        print(f"   VAD: {best['vad_filter']}")
        print(f"   Confidence: {best['avg_confidence']:.3f}")
        print(f"   Memory: {best['peak_memory_mb']:.1f} MB")
    
    print(f"\n‚úì –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:")
    print(f"   CSV: {csv_file}")
    print(f"   Markdown: {md_file}")


if __name__ == "__main__":
    main()

